#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
math_processing.py - æ•°å­¦å…¬å¼å¤„ç†æ¨¡å— - å®šç•Œç¬¦è§£æã€ä¿®å¤ã€è½¬æ¢

ä» ocr_to_examx.py æå–çš„å…±äº«å·¥å…·å‡½æ•°ï¼Œä¾› exam å’Œ handout è½¬æ¢å™¨ä½¿ç”¨ã€‚

ç”Ÿæˆæ—¶é—´: è‡ªåŠ¨æå–
æºæ–‡ä»¶: tools/core/ocr_to_examx.py
"""

from enum import Enum, auto
import re

# ============================================================
# æ•°å­¦å…¬å¼å¤„ç†æ¨¡å— - å®šç•Œç¬¦è§£æã€ä¿®å¤ã€è½¬æ¢
# ============================================================

CHINESE_MATH_SEPARATORS = {
    'connectors': ['å³', 'ä¸', 'æˆ–', 'ä¸”', 'æ•…', 'åˆ™', 'æ‰€ä»¥', 'å› æ­¤', 'å› ä¸º', 'ç”±äº', 'æ ¹æ®', 'æ˜¾ç„¶', 'å¯çŸ¥', 'å¯å¾—', 'äºæ˜¯', 'ä»è€Œ'],
    'math_objects': ['ç›´çº¿', 'æ›²çº¿', 'å¹³é¢', 'å‡½æ•°', 'æ–¹ç¨‹', 'åœ†', 'ç‚¹', 'æ¤­åœ†', 'åŒæ›²çº¿', 'æŠ›ç‰©çº¿', 'å‘é‡', 'çŸ©é˜µ', 'é›†åˆ', 'åŒºé—´'],
    'verbs': ['è®¾', 'ä»¤', 'è‹¥', 'å½“', 'æ—¶', 'æœ‰', 'å¾—', 'çŸ¥', 'è¿‡', 'å–', 'ä½œ'],
}


class TokenType(Enum):
    TEXT = auto()
    DOLLAR_SINGLE = auto()
    DOLLAR_DOUBLE = auto()
    LATEX_OPEN = auto()
    LATEX_CLOSE = auto()
    RIGHT_BOUNDARY = auto()
    NEWLINE = auto()
    EOF = auto()




class MathStateMachine:
    r"""æ•°å­¦æ¨¡å¼çŠ¶æ€æœº - ç»Ÿä¸€è§£æ/è§„èŒƒæ‰€æœ‰æ•°å­¦å®šç•Œç¬¦

    è®¾è®¡ç›®æ ‡ï¼š
    1. æ”¯æŒæ··åˆå‡ºç°çš„ $ ... $ã€$$ ... $$ã€\( ... \) ä»¥åŠ OCR ç”Ÿæˆçš„ \right. $$ ç­‰ç•¸å½¢è¾¹ç•Œ
    2. å°†æ‰€æœ‰æ˜¾ç¤º/è¡Œå†…æ•°å­¦ç»Ÿä¸€è§„èŒƒä¸ºè¡Œå†…å½¢å¼ï¼š\( ... \)ï¼ˆä¸ examx åŒ…å…¼å®¹ï¼‰
    3. ä¿æŒå·²æœ‰æ­£ç¡®çš„ \( ... \) / \) ä¸è¢«äºŒæ¬¡åŒ…è£¹
    4. é˜²æ­¢è·¨è¡Œå•ç¾å…ƒæœªé—­åˆé€ æˆåå¹¶åç»­æ–‡æœ¬
    """

    def preprocess_multiline_math(self, text: str) -> str:
        """é¢„å¤„ç†å¤šè¡Œæ•°å­¦ç¯å¢ƒï¼ˆä¿®å¤ P0-001, P0-002ï¼‰

        å¤„ç†è·¨å¤šè¡Œçš„ $$...array/cases...$$ å—ï¼Œé¿å…è¢«é€è¡Œæ‹†æ•£
        
        ğŸ†• v1.9.3ï¼šä¿®å¤ T008/T017 é—®é¢˜
        - åªåˆå¹¶å†’å·åˆ†éš”çš„ $$æ ‡ç­¾$$ï¼š$$å…¬å¼$$ æ¨¡å¼
        - ä¸åˆå¹¶é€—å·/é¡¿å·åˆ†éš”çš„ç‹¬ç«‹å˜é‡ $$P$$ï¼Œ$$B$$ æ¨¡å¼
        """
        # ğŸ†• ä¿®å¤ P0-001a: åªåˆå¹¶å†’å·åˆ†éš”çš„æ¨¡å¼ï¼ˆæ ‡ç­¾ï¼šå…¬å¼ï¼‰
        # ä¾‹å¦‚: $$C$$ï¼š$$x^{2}$$ â†’ $$Cï¼šx^{2}$$
        # ğŸ”§ v1.9.3: ç§»é™¤é€—å·/é¡¿å·/å¥å·/åˆ†å·ï¼Œè¿™äº›åˆ†éš”çš„åº”è¯¥ä¿æŒç‹¬ç«‹
        text = re.sub(r'\$\$([^$]+)\$\$([ï¼š])\$\$([^$]+)\$\$', r'$$\1\2\3$$', text)

        # ğŸ†• v1.9.8: å¤„ç†åµŒå¥—çš„å¤šè¡Œæ•°å­¦ç¯å¢ƒ
        # ä¾‹å¦‚: $$\left\{...\Rightarrow \left\{...\right.\right.\ $$
        # è¿™ç§åµŒå¥—ç»“æ„æ— æ³•è¢«å•å±‚æ­£åˆ™åŒ¹é…ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        def process_nested_multiline(text):
            r"""å¤„ç†åµŒå¥—çš„ \left...\right å¤šè¡Œæ•°å­¦ç¯å¢ƒ"""
            # åŒ¹é… $$\left å¼€å¤´ï¼Œåˆ°åµŒå¥—çš„ \right.\right.\ $$ ç»“å°¾çš„å—
            # [\s\\]* åŒ¹é…ç©ºç™½å’Œåæ–œæ ï¼ˆå¤„ç† \right.\ \right.\ $$ æ ¼å¼ï¼‰
            pattern = re.compile(
                r'\$\$\s*\\left.*?\\right\.[\s\\]*\\right\.[\s\\]*\$\$',
                re.DOTALL
            )

            def replace_nested(match):
                content = match.group(0)
                # æå– \left åˆ°æœ€åä¸€ä¸ª \right. çš„å†…å®¹ï¼ˆè´ªå©ªåŒ¹é…ï¼‰
                inner = re.search(r'\\left.*\\right\.[\s\\]*\\right\.', content, re.DOTALL)
                if inner:
                    return r'\(' + inner.group(0) + r'\)'
                # é™çº§å¤„ç†
                inner = content.strip()
                if inner.startswith('$$'):
                    inner = inner[2:]
                if inner.endswith('$$'):
                    inner = inner[:-2]
                return r'\(' + inner.strip() + r'\)'

            return pattern.sub(replace_nested, text)

        text = process_nested_multiline(text)

        # ğŸ†• ä¿®å¤ P0-002: å¤„ç† \right.\ $$ è·¨è¡Œè¾¹ç•Œæ¨¡å¼
        # æƒ…å†µ1: \right.\ $$ ï¼ˆåæ–œæ +ç©ºæ ¼+åŒç¾å…ƒï¼‰
        # æ³¨æ„ï¼š\ æ˜¯ä¸¤ä¸ªå­—ç¬¦ï¼šåæ–œæ å’Œç©ºæ ¼ï¼Œ\left\{ æ˜¯backslash-left-backslash-brace
        # (?:\\[\{\[\(])? è¡¨ç¤ºå¯é€‰çš„ "\{" æˆ– "\[" æˆ– "\("
        pattern_backslash_space = re.compile(
            r'\$\$\s*\\left(?:\\[\{\[\(])?\s*\\begin\{(array|cases|matrix|pmatrix|bmatrix|vmatrix)\}.*?\\end\{\1\}\s*\\right(?:\\[\}\]\)])?\.?\s*\\ \$\$',
            re.DOTALL
        )
        
        def extract_content(match_obj):
            # Extract the \left...\right. part
            content = re.search(r'\\left.*?\\right(?:\\[\}\]\)])?\.?', match_obj.group(0), re.DOTALL)
            return r'\(' + content.group(0) + r'\)'
        
        text = pattern_backslash_space.sub(extract_content, text)

        # æƒ…å†µ2: \right.\\ $$ ï¼ˆåŒåæ–œæ +ç©ºæ ¼+åŒç¾å…ƒï¼‰
        pattern_double_backslash = re.compile(
            r'\$\$\s*\\left(?:\\[\{\[\(])?\s*\\begin\{(array|cases|matrix|pmatrix|bmatrix|vmatrix)\}.*?\\end\{\1\}\s*\\right(?:\\[\}\]\)])?\.?\s*\\\\ \$\$',
            re.DOTALL
        )
        text = pattern_double_backslash.sub(extract_content, text)

        # åŒ¹é… $$...$$ å—ï¼ŒåŒ…æ‹¬è·¨è¡Œçš„ array/cases/matrix ç¯å¢ƒï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        pattern = re.compile(
            r'\$\$\s*\\left(?:\\[\{\[\(])?\s*\\begin\{(array|cases|matrix|pmatrix|bmatrix|vmatrix)\}.*?\\end\{\1\}\s*\\right(?:\\[\}\]\)])?\.?\s*\$\$',
            re.DOTALL
        )

        def replace_multiline(match):
            # ğŸ”§ v1.9.7: ä¿®å¤å†…éƒ¨ \left|...\right| å¯¼è‡´çš„æˆªæ–­é—®é¢˜
            # åŸæ¥çš„æ­£åˆ™ \\left.*?\\right ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œä¼šåœ¨é‡åˆ°ç¬¬ä¸€ä¸ª \right æ—¶åœæ­¢
            # å½“æ–¹ç¨‹ç»„å†…éƒ¨åŒ…å« \left|...\right|ï¼ˆç»å¯¹å€¼ï¼‰æ—¶ä¼šé”™è¯¯æˆªæ–­
            #
            # ä¿®å¤æ–¹æ¡ˆï¼šä½¿ç”¨è´ªå©ªåŒ¹é… .* é…åˆ \right\. æ¥åŒ¹é…æœ€å¤–å±‚çš„ \right.
            # å› ä¸ºå¤–å±‚ pattern å·²ç»ç¡®ä¿äº†æ•´ä¸ªå—çš„æ­£ç¡®æ€§ï¼Œè¿™é‡Œåªéœ€è¦æå– \left...\right. éƒ¨åˆ†
            content = re.search(r'\\left.*\\right\.', match.group(0), re.DOTALL)
            if content:
                return r'\(' + content.group(0) + r'\)'
            # é™çº§ï¼šå¦‚æœæ²¡æœ‰ \right.ï¼Œå°è¯•åŒ¹é… \right åè·Ÿå…¶ä»–æ‹¬å·
            content = re.search(r'\\left.*\\right(?:\\[\}\]\)])?', match.group(0), re.DOTALL)
            if content:
                return r'\(' + content.group(0) + r'\)'
            # æœ€åé™çº§ï¼šè¿”å›å»æ‰ $$ çš„åŸå†…å®¹
            inner = match.group(0).strip()
            if inner.startswith('$$'):
                inner = inner[2:]
            if inner.endswith('$$'):
                inner = inner[:-2]
            return r'\(' + inner.strip() + r'\)'

        return pattern.sub(replace_multiline, text)

    def tokenize(self, text: str) -> List:
        tokens = []
        i = 0
        n = len(text)
        while i < n:
            # ğŸ”¥ v1.8.6ï¼šå¢å¼º \right. åçš„ OCR è¾¹ç•Œæ£€æµ‹ï¼ˆä¿®å¤ P0-001ï¼‰
            # å¤„ç† \right. åå¯èƒ½è·Ÿéšçš„å„ç§ç•¸å½¢æ ¼å¼ï¼š
            # - \right. $$
            # - \right. $
            # - \right.\ $$  ï¼ˆåæ–œæ ç©ºæ ¼ï¼ŒP0-CRITICALï¼‰
            # - \right.\\ $$  ï¼ˆåŒåæ–œæ ç©ºæ ¼ï¼‰
            # - \right.  $$  ï¼ˆå¤šä¸ªç©ºæ ¼ï¼‰
            # - \right.ï¼Œï¼ˆç›´æ¥è·Ÿä¸­æ–‡æ ‡ç‚¹ï¼‰
            if text[i:].startswith(r'\right.'):
                j = i + 7  # è·³è¿‡ \right.
                found_boundary = False

                # ğŸ†• v1.9.3ï¼šä¿®å¤ \right.\ $$ å¤„ç†
                # ç”Ÿæˆ RIGHT_BOUNDARY token åï¼Œè¿˜è¦ç”Ÿæˆ DOLLAR_DOUBLE token
                # è¿™æ · process å‡½æ•°æ‰èƒ½æ­£ç¡®è¯†åˆ«æ•°å­¦æ¨¡å¼çš„ç»“æŸ

                # æƒ…å†µ1ï¼š\right.\ $$ï¼ˆåæ–œæ +ç©ºæ ¼+åŒç¾å…ƒï¼ŒP0-CRITICALï¼‰
                if j < n - 3 and text[j:j+4] == r'\ $$':
                    tokens.append((TokenType.RIGHT_BOUNDARY, r'\right.', i))
                    tokens.append((TokenType.DOLLAR_DOUBLE, '$$', j + 2))  # æ·»åŠ ç»“æŸç¬¦
                    i = j + 4
                    found_boundary = True

                # æƒ…å†µ2ï¼š\right.\\ $$ï¼ˆåŒåæ–œæ +ç©ºæ ¼+åŒç¾å…ƒï¼‰
                elif j < n - 4 and text[j:j+5] == r'\\ $$':
                    tokens.append((TokenType.RIGHT_BOUNDARY, r'\right.', i))
                    tokens.append((TokenType.DOLLAR_DOUBLE, '$$', j + 3))  # æ·»åŠ ç»“æŸç¬¦
                    i = j + 5
                    found_boundary = True

                # æƒ…å†µ3ï¼š\right. $$ï¼ˆç©ºæ ¼+åŒç¾å…ƒï¼‰
                elif j < n - 1 and text[j] == ' ':
                    # è·³è¿‡å¤šä¸ªç©ºæ ¼
                    k = j
                    while k < n and text[k] == ' ':
                        k += 1
                    if k < n - 1 and text[k:k+2] == '$$':
                        tokens.append((TokenType.RIGHT_BOUNDARY, r'\right.', i))
                        tokens.append((TokenType.DOLLAR_DOUBLE, '$$', k))  # æ·»åŠ ç»“æŸç¬¦
                        i = k + 2
                        found_boundary = True

                # æƒ…å†µ4ï¼š\right.$$ï¼ˆç›´æ¥è·ŸåŒç¾å…ƒï¼Œæ— ç©ºæ ¼ï¼‰
                elif j < n - 1 and text[j:j+2] == '$$':
                    tokens.append((TokenType.RIGHT_BOUNDARY, r'\right.', i))
                    tokens.append((TokenType.DOLLAR_DOUBLE, '$$', j))  # æ·»åŠ ç»“æŸç¬¦
                    i = j + 2
                    found_boundary = True

                # æƒ…å†µ5ï¼š\right. $ï¼ˆå•ç¾å…ƒï¼‰- è¿™ç§æƒ…å†µæ¯”è¾ƒç‰¹æ®Šï¼Œä¿æŒåŸæ ·
                elif j < n and text[j] == '$' and (j + 1 >= n or text[j+1] != '$'):
                    tokens.append((TokenType.RIGHT_BOUNDARY, r'\right.', i))
                    tokens.append((TokenType.DOLLAR_SINGLE, '$', j))  # æ·»åŠ ç»“æŸç¬¦
                    i = j + 1
                    found_boundary = True

                # æƒ…å†µ6ï¼š\right.\)ï¼ˆå·²ç»æ­£ç¡®é—­åˆï¼‰
                elif j < n - 1 and text[j:j+2] == r'\)':
                    # è¿™æ˜¯æ­£ç¡®çš„æ ¼å¼ï¼Œä¿æŒåŸæ ·
                    tokens.append((TokenType.TEXT, r'\right.', i))
                    i += 7
                    found_boundary = True

                # æƒ…å†µ7ï¼š\right. åç›´æ¥è·Ÿä¸­æ–‡æ ‡ç‚¹ï¼ˆï¼Œã€‚ï¼›ï¼šç­‰ï¼‰
                elif j < n and text[j] in 'ï¼Œã€‚ï¼›ï¼šã€ï¼ï¼Ÿ':
                    # OCR é”™è¯¯ï¼šç¼ºå°‘é—­åˆç¬¦å·
                    # æ’å…¥ \right.\) æ¥é—­åˆæ•°å­¦æ¨¡å¼ï¼Œæ ‡ç‚¹ä¿æŒåœ¨æ•°å­¦æ¨¡å¼å¤–
                    tokens.append((TokenType.RIGHT_BOUNDARY, r'\right.', i))
                    i = j  # ä¸è·³è¿‡æ ‡ç‚¹ï¼Œè®©åç»­å¤„ç†å°†å…¶ä½œä¸ºæ™®é€šæ–‡æœ¬
                    found_boundary = True

                if not found_boundary:
                    # ä¸æ˜¯è¾¹ç•Œé”™è¯¯ï¼Œä¿æŒåŸæ ·
                    tokens.append((TokenType.TEXT, r'\right.', i))
                    i += 7

                if found_boundary:
                    continue

            # $$ æ˜¾ç¤ºæ•°å­¦
            if i < n - 1 and text[i:i+2] == '$$':
                tokens.append((TokenType.DOLLAR_DOUBLE, '$$', i))
                i += 2
                continue

            # å• $ è¡Œå†…æ•°å­¦
            if text[i] == '$':
                tokens.append((TokenType.DOLLAR_SINGLE, '$', i))
                i += 1
                continue

            # \( ä¸ \)
            if i < n - 1 and text[i:i+2] == r'\(':
                tokens.append((TokenType.LATEX_OPEN, r'\(', i))
                i += 2
                continue
            if i < n - 1 and text[i:i+2] == r'\)':
                tokens.append((TokenType.LATEX_CLOSE, r'\)', i))
                i += 2
                continue

            # æ™®é€šæ–‡æœ¬å—æ”¶é›†
            j = i
            while j < n:
                if text[j] in '$\n':
                    break
                if j < n - 1 and text[j:j+2] in [r'\(', r'\)', '$$']:
                    break
                if text[j:].startswith(r'\right.'):
                    break
                j += 1
            if j > i:
                tokens.append((TokenType.TEXT, text[i:j], i))
                i = j
            else:
                tokens.append((TokenType.TEXT, text[i], i))
                i += 1
        return tokens

    def fix_malformed_patterns(self, text: str) -> str:
        r"""ä¿®å¤æ ¼å¼é”™è¯¯çš„æ•°å­¦æ¨¡å¼ï¼ˆå¢å¼ºç‰ˆ v1.9.2ï¼‰

        ğŸ†• v1.9.2: å¤„ç†æ›´å¤šçš„ç•¸å½¢æ¨¡å¼
        - åµŒå¥—å®šç•Œç¬¦ï¼š\(P,B\(ï¼Œ\)C,D\) â†’ \(P,B\)ï¼Œ\(C,D\)
        - åå‘åµŒå¥—ï¼š\)...\( â†’ ä¿®æ­£ä¸ºæ­£ç¡®é¡ºåº
        """
        import re

        # 1. åˆ é™¤ç©ºæ•°å­¦æ¨¡å¼ \(\)
        text = re.sub(r'\\\(\s*\\\)', '', text)

        # 2. ä¿®å¤è¿ç»­å®šç•Œç¬¦ï¼ˆè¿­ä»£å¤„ç†ï¼Œæœ€å¤š3æ¬¡ï¼‰
        for _ in range(3):
            before = text
            # \(\( â†’ \(
            text = re.sub(r'\\\(\\\(', r'\\(', text)
            # \)\) â†’ \)
            text = re.sub(r'\\\)\\\)', r'\\)', text)
            if text == before:
                break

        # 3. ä¿®å¤é”™è¯¯åµŒå¥— \((\) â†’ (
        text = re.sub(r'\\\(\(\\\)', '(', text)

        # 4. ä¿®å¤ \)(\( â†’ )(  (é”™è¯¯çš„å®šç•Œç¬¦åŒ…è£¹æ‹¬å·)
        # ğŸ†• v1.9.11ï¼šæ”¹ä¸ºä¿å®ˆç­–ç•¥ï¼Œåªå¤„ç†çœ‹èµ·æ¥åƒé”™è¯¯åµŒå¥—çš„æƒ…å†µ
        # ä¸å¤„ç†åˆæ³•çš„ \(...\)(\(...\)) ç»“æ„ï¼ˆå¦‚æ¡ä»¶è¡¨è¾¾å¼ï¼‰
        # åªå¤„ç†æ˜æ˜¾é”™è¯¯çš„æƒ…å†µï¼š\)(\( ä¸”å‰é¢çš„ \( å·²é—­åˆ
        # æš‚æ—¶ç¦ç”¨è¿™ä¸ªè§„åˆ™ï¼Œå› ä¸ºå®ƒä¼šç ´å \(x=16\)(\(y>0\)) è¿™ç§åˆæ³•ç»“æ„
        # text = re.sub(r'\\\)\(\\\(', ')(', text)
        
        # ğŸ†• v1.9.2: ä¿®å¤åµŒå¥—å®šç•Œç¬¦ä¸­çš„ä¸­æ–‡æ ‡ç‚¹
        # æ¨¡å¼: \(æ ‡ç‚¹\) â†’ æ ‡ç‚¹ (å½“æ ‡ç‚¹æ˜¯ç‹¬ç«‹çš„æ•°å­¦å—æ—¶)
        # ä¾‹å¦‚: \(P,B\(ï¼Œ\)C,D\) ä¸­çš„ \(ï¼Œ\) åº”è¯¥å˜æˆ ï¼Œ
        chinese_punct = ['ï¼Œ', 'ã€‚', 'ï¼›', 'ï¼š', 'ã€', 'ï¼', 'ï¼Ÿ']
        for punct in chinese_punct:
            # åŒ¹é… \(æ ‡ç‚¹\) æ¨¡å¼ï¼ˆæ ‡ç‚¹å•ç‹¬åœ¨æ•°å­¦å—ä¸­ï¼‰
            pattern = r'\\\(' + re.escape(punct) + r'\\\)'
            text = re.sub(pattern, punct, text)
        
        # ä¿®å¤ \(ï¼Œ\therefore\) è¿™ç±»æ¨¡å¼ â†’ ï¼Œ\(\therefore\)
        text = re.sub(r'\\\(([ï¼Œã€‚ï¼›ï¼šã€ï¼ï¼Ÿ])\\\\therefore\\\)', r'\1\\(\\therefore\\)', text)
        
        # ä¿®å¤ \(ï¼Œ\) åé¢ç´§è·Ÿå†…å®¹çš„æƒ…å†µï¼ˆå¯èƒ½æ˜¯åµŒå¥—é”™è¯¯ï¼‰
        # \(å†…å®¹\(ï¼Œ\)å†…å®¹\) â†’ \(å†…å®¹\)ï¼Œ\(å†…å®¹\)
        for punct in chinese_punct:
            pattern = rf'(\\\([^)]+)\\\({re.escape(punct)}\\\)([^)]+\\\))'
            replacement = r'\1\\)' + punct + r'\\(\2'
            for _ in range(3):
                new_text = re.sub(pattern, replacement, text)
                if new_text == text:
                    break
                text = new_text

        return text

    def normalize_punctuation_in_math(self, text: str) -> str:
        r"""è§„èŒƒåŒ–æ•°å­¦æ¨¡å¼å†…çš„å…¨è§’æ ‡ç‚¹ï¼ˆå¢å¼ºç‰ˆ v1.9.1ï¼‰

        ğŸ†• v1.9.1ï¼šæ·»åŠ æ›´å®Œæ•´çš„ä¸­æ–‡æ ‡ç‚¹æ˜ å°„
        - é¡¿å·ã€å†’å·ã€å¥å·ç­‰
        - ä¿æŠ¤ \text{}, \mbox{}, \mathrm{} å†…çš„ä¸­æ–‡æ ‡ç‚¹
        ğŸ†• P1-003ï¼šæ‰©å±•æ ‡ç‚¹æ˜ å°„åˆ—è¡¨ï¼Œæ·»åŠ $$...$$å¤„ç†
        """
        import re

        # æ ‡ç‚¹æ›¿æ¢æ˜ å°„ï¼ˆåœ¨æ•°å­¦æ¨¡å¼å†…ä½¿ç”¨åŠè§’ï¼‰
        punct_map = {
            'ï¼Œ': ',',
            'ï¼›': ';',
            'ï¼š': ':',
            'ï¼ˆ': '(',
            'ï¼‰': ')',
            'ã€': ',',  # é¡¿å·è½¬ä¸ºé€—å·
            'ã€‚': '.',
            'ï¼': '!',
            'ï¼Ÿ': '?',
            'ã€': '[',
            'ã€‘': ']',
            'ã€”': '[',
            'ã€•': ']',
            'ã€Œ': '"',
            'ã€': '"',
            # ğŸ†• v1.9.9: P2-9 è¡¥å……æ›´å¤šä¸­æ–‡æ ‡ç‚¹
            'ã€': '"',
            'ã€': '"',
            '"': '"',
            '"': '"',
            ''': "'",
            ''': "'",
            'â€”': '-',
            'â€¦': '...',
        }

        # ğŸ†• v1.9.9: P1-6 æå–å…¬å…±çš„æ–‡æœ¬ä¿æŠ¤é€»è¾‘
        def protect_text_commands(content: str, protected: list) -> str:
            """ä¿æŠ¤ \\text{}, \\mbox{} ç­‰å‘½ä»¤å†…çš„å†…å®¹"""
            def save_text(m):
                protected.append(m.group(0))
                return f"@@TEXT_{len(protected)-1}@@"

            content = re.sub(r'\\text\{[^}]*\}', save_text, content)
            content = re.sub(r'\\mbox\{[^}]*\}', save_text, content)
            content = re.sub(r'\\mathrm\{[^}]*\}', save_text, content)
            content = re.sub(r'\\textbf\{[^}]*\}', save_text, content)
            content = re.sub(r'\\textit\{[^}]*\}', save_text, content)
            return content

        def restore_protected(content: str, protected: list) -> str:
            """æ¢å¤è¢«ä¿æŠ¤çš„å†…å®¹"""
            for i, p in enumerate(protected):
                content = content.replace(f"@@TEXT_{i}@@", p)
            return content

        # ğŸ†• v1.9.2: ä½¿ç”¨åŸºäºä½ç½®çš„åŒ¹é…æ¥å¤„ç†åµŒå¥—æ‹¬å·
        def process_all_math_blocks(text: str) -> str:
            """é€ä¸ªå¤„ç†æ‰€æœ‰æ•°å­¦å—ï¼Œæ”¯æŒåµŒå¥—æ‹¬å·"""
            result = []
            i = 0
            n = len(text)
            
            while i < n:
                # æŸ¥æ‰¾ \(
                if i < n - 1 and text[i:i+2] == r'\(':
                    # æ‰¾åˆ°å¯¹åº”çš„ \)
                    start = i
                    depth = 1
                    j = i + 2
                    
                    # ğŸ†• v1.9.8: ä¿®å¤ P0-2 è¾¹ç•Œæ£€æŸ¥ï¼Œj < n è€Œé j < n - 1
                    while j < n and depth > 0:
                        if j < n - 1 and text[j:j+2] == r'\(':
                            depth += 1
                            j += 2
                        elif j < n - 1 and text[j:j+2] == r'\)':
                            depth -= 1
                            if depth == 0:
                                break
                            j += 2
                        else:
                            j += 1
                    
                    if depth == 0:
                        # æˆåŠŸåŒ¹é…ï¼Œå¤„ç†å†…å®¹
                        math_content = text[start+2:j]

                        # ğŸ†• v1.9.9: ä½¿ç”¨æå–çš„è¾…åŠ©å‡½æ•°
                        protected = []
                        processed = protect_text_commands(math_content, protected)

                        # æ›¿æ¢å…¨è§’æ ‡ç‚¹
                        for full, half in punct_map.items():
                            processed = processed.replace(full, half)

                        # æ¢å¤ä¿æŠ¤çš„å†…å®¹
                        processed = restore_protected(processed, protected)

                        result.append(r'\(' + processed + r'\)')
                        i = j + 2
                    else:
                        # æœªèƒ½æ‰¾åˆ°åŒ¹é…çš„ \)ï¼Œä¿æŒåŸæ ·
                        result.append(text[i])
                        i += 1
                else:
                    result.append(text[i])
                    i += 1
            
            return ''.join(result)
        
        text = process_all_math_blocks(text)
        
        # ğŸ†• P1-003: åŒæ ·å¤„ç† $$...$$ å†…çš„æ ‡ç‚¹ï¼ˆè½¬æ¢å‰ï¼‰
        def replace_in_dollar(match):
            content = match.group(1)
            for full, half in punct_map.items():
                content = content.replace(full, half)
            return '$$' + content + '$$'
        
        text = re.sub(r'\$\$([^$]+)\$\$', replace_in_dollar, text)

        return text

    def split_colon_from_math(self, text: str) -> str:
        r"""åˆ†ç¦»æ•°å­¦æ¨¡å¼å†…çš„ä¸­æ–‡å†’å·
        
        æ¨¡å¼ï¼š\(æ ‡ç­¾ï¼šå…¬å¼\) â†’ \(æ ‡ç­¾\)ï¼š\(å…¬å¼\)
        """
        import re

        # æ¨¡å¼1: \(å•å­—æ¯ï¼šå…¬å¼\)
        pattern1 = r'\\\(([A-Za-z])ï¼š([^)]+)\\\)'
        text = re.sub(pattern1, r'\\(\1\\)ï¼š\\(\2\\)', text)
        
        # æ¨¡å¼2: \(å˜é‡_ä¸‹æ ‡ï¼šå…¬å¼\)
        pattern2 = r'\\\(([a-z]_\{[^}]+\})ï¼š([^)]+)\\\)'
        text = re.sub(pattern2, r'\\(\1\\)ï¼š\\(\2\\)', text)
        
        # æ¨¡å¼3: \(å˜é‡ä¸‹æ ‡ï¼šå…¬å¼\) (æ— èŠ±æ‹¬å·)
        pattern3 = r'\\\(([a-z]_\d+)ï¼š([^)]+)\\\)'
        text = re.sub(pattern3, r'\\(\1\\)ï¼š\\(\2\\)', text)
        
        return text
    
    def fix_math_symbol_chinese_boundary(self, text: str) -> str:
        r"""ä¿®å¤æ•°å­¦ç¬¦å·åç›´æ¥è·Ÿä¸­æ–‡çš„è¾¹ç•Œé—®é¢˜
        
        å¤„ç†æ¨¡å¼ï¼š\(symbolä¸­æ–‡...\) â†’ \(symbol\)ä¸­æ–‡...\)
        """
        import re
        
        # éœ€è¦åˆ†ç¦»çš„æ•°å­¦ç¬¦å·åˆ—è¡¨
        symbols = [
            r'\\therefore',
            r'\\because', 
            r'\\subset',
            r'\\supset',
            r'\\in',
            r'\\notin',
            r'\\cap',
            r'\\cup',
            r'\\parallel',
            r'\\perp',
            r'\\forall',
            r'\\exists',
            r'\\Rightarrow',
            r'\\Leftrightarrow',
            r'\\sim',
            r'\\cong',
            r'\\equiv',
        ]
        
        # å¤šæ¬¡è¿­ä»£å¤„ç†ï¼Œç›´åˆ°æ²¡æœ‰æ›´å¤šåŒ¹é…
        max_iterations = 5
        for _ in range(max_iterations):
            changed = False
            for sym in symbols:
                # åŒ¹é… \(å‰ç¼€symbolä¸­æ–‡åç¼€\) æ¨¡å¼
                # å…¶ä¸­ symbol åé¢ç›´æ¥è·Ÿä¸­æ–‡
                pattern = rf'(\\\()([^)]*?)({sym})([\u4e00-\u9fa5]+)([^)]*?)(\\\))'
                
                def replace_fn(m):
                    nonlocal changed
                    changed = True
                    
                    open_paren = m.group(1)   # \(
                    before = m.group(2)        # symbol å‰çš„å†…å®¹
                    symbol = m.group(3)        # æ•°å­¦ç¬¦å·
                    chinese = m.group(4)       # ä¸­æ–‡
                    after = m.group(5)         # ä¸­æ–‡åçš„å†…å®¹
                    close_paren = m.group(6)   # \)
                    
                    # é‡ç»„ï¼š\(å‰ç¼€+symbol\)ä¸­æ–‡\(åç¼€\)
                    result = ''
                    
                    # å‰ç¼€éƒ¨åˆ†
                    if before.strip():
                        result += open_paren + before + symbol + close_paren
                    else:
                        result += open_paren + symbol + close_paren
                    
                    # ä¸­æ–‡éƒ¨åˆ†ï¼ˆåœ¨æ•°å­¦æ¨¡å¼å¤–ï¼‰
                    result += chinese
                    
                    # åç¼€éƒ¨åˆ† - é€’å½’å¤„ç†
                    if after.strip():
                        result += open_paren + after + close_paren
                    
                    return result
                
                text = re.sub(pattern, replace_fn, text, flags=re.DOTALL)
            
            if not changed:
                break
        
        # æ¸…ç†ç©ºçš„æ•°å­¦æ¨¡å¼
        text = re.sub(r'\\\(\s*\\\)', '', text)
        
        return text

    def split_chinese_from_math(self, text: str) -> str:
        """å°†ä¸­æ–‡è¯æ±‡ä»æ•°å­¦æ¨¡å¼ä¸­åˆ†ç¦» - é‡å†™ç‰ˆ
        
        ç­–ç•¥ï¼šå°†å¼€å¤´å’Œç»“å°¾çš„ä¸­æ–‡ç§»åˆ°æ•°å­¦æ¨¡å¼å¤–éƒ¨ï¼Œè€Œä¸æ˜¯åœ¨å†…éƒ¨æ’å…¥å®šç•Œç¬¦
        """
        import re
        
        def process_math_block(match):
            content = match.group(1)
            original = match.group(0)
            
            # å¦‚æœå†…å®¹ä¸ºç©ºæˆ–åªæœ‰ç©ºç™½ï¼Œä¿æŒåŸæ ·
            if not content.strip():
                return original
            
            prefix = ''
            suffix = ''
            core = content
            
            # æ£€æµ‹å¹¶æå–å¼€å¤´çš„ä¸­æ–‡
            chinese_start = re.match(r'^([\u4e00-\u9fa5ï¼Œã€‚ï¼›ï¼šã€ï¼ï¼Ÿ\s]+)', core)
            if chinese_start:
                prefix = chinese_start.group(1)
                core = core[len(prefix):]
            
            # æ£€æµ‹å¹¶æå–ç»“å°¾çš„ä¸­æ–‡
            chinese_end = re.search(r'([\u4e00-\u9fa5ï¼Œã€‚ï¼›ï¼šã€ï¼ï¼Ÿ\s]+)$', core)
            if chinese_end:
                suffix = chinese_end.group(1)
                core = core[:-len(suffix)]
            
            # å¦‚æœæ ¸å¿ƒå†…å®¹è¢«å®Œå…¨ç§»é™¤ï¼Œè¯´æ˜åŸæœ¬å°±ä¸åº”è¯¥æ˜¯æ•°å­¦æ¨¡å¼
            if not core.strip():
                return prefix + suffix
            
            # é‡ç»„ï¼šä¸­æ–‡å‰ç¼€ + \(æ ¸å¿ƒå…¬å¼\) + ä¸­æ–‡åç¼€
            result = prefix + r'\(' + core + r'\)' + suffix
            
            # æ¸…ç†å¯èƒ½äº§ç”Ÿçš„ç©ºæ•°å­¦æ¨¡å¼
            result = re.sub(r'\\\(\s*\\\)', '', result)
            
            return result
        
        # å¤„ç†æ‰€æœ‰ \(...\) å—
        return re.sub(r'\\\(([^)]*?)\\\)', process_math_block, text, flags=re.DOTALL)

    def balance_delimiters(self, text: str) -> str:
        r"""å¹³è¡¡æ•°å­¦å®šç•Œç¬¦ï¼ˆå¢å¼ºç‰ˆ v1.9.3ï¼‰

        ğŸ†• v1.9.3 ä¿®å¤:
        - ç§»é™¤äº†é”™è¯¯çš„ connector å‰æ·»åŠ  \) çš„é€»è¾‘
        - è¯¥é€»è¾‘å‡è®¾ \therefore ç­‰ç¬¦å·å‰ä¸€å®šæœ‰æ•°å­¦å†…å®¹éœ€è¦é—­åˆ
        - ä½†å®é™…ä¸Šè¿™äº›ç¬¦å·å¯èƒ½å‡ºç°åœ¨è¡Œé¦–ï¼Œå‰é¢æ˜¯æ™®é€šæ–‡æœ¬æˆ–ä¸­æ–‡æ ‡ç‚¹

        ğŸ†• v1.9.2 æ”¹è¿›:
        1. æ”¯æŒè·¨è¡Œæ•°å­¦ç¯å¢ƒï¼ˆarray/casesï¼‰çš„å¹³è¡¡æ£€æŸ¥
        3. å…¨å±€å¹³è¡¡æ£€æŸ¥å’Œä¿®å¤
        """
        import re

        # æ­¥éª¤1ï¼šå¤„ç†è·¨è¡Œæ•°å­¦ç¯å¢ƒ
        # æ£€æµ‹ \(\left\{ \begin{array} ä½†æ²¡æœ‰å¯¹åº”çš„ \end{array} \right.\)
        lines = text.split('\n')
        processed_lines = []
        pending_close = 0  # ç´¯ç§¯éœ€è¦é—­åˆçš„æ•°é‡
        in_multiline_math = False
        
        for i, line in enumerate(lines):
            if line.strip().startswith('%'):
                processed_lines.append(line)
                continue

            # æ£€æµ‹è·¨è¡Œæ•°å­¦ç¯å¢ƒå¼€å§‹
            if re.search(r'\\\(.*\\begin\{(array|cases|matrix|pmatrix|bmatrix)\}', line) and \
               not re.search(r'\\end\{(array|cases|matrix|pmatrix|bmatrix)\}.*\\\)', line):
                in_multiline_math = True
                pending_close += 1
            
            # æ£€æµ‹è·¨è¡Œæ•°å­¦ç¯å¢ƒç»“æŸ
            # ğŸ†• v1.9.8: æ”¹è¿›åµŒå¥—æ£€æµ‹ - åªæœ‰å½“ \end æ•°é‡ >= \begin æ•°é‡æ—¶æ‰è®¤ä¸ºç¯å¢ƒç»“æŸ
            if in_multiline_math and re.search(r'\\end\{(array|cases|matrix|pmatrix|bmatrix)\}', line):
                # ç»Ÿè®¡è¿™è¡Œä¸­ \begin å’Œ \end çš„æ•°é‡
                begin_count = len(re.findall(r'\\begin\{(array|cases|matrix|pmatrix|bmatrix)\}', line))
                end_count = len(re.findall(r'\\end\{(array|cases|matrix|pmatrix|bmatrix)\}', line))

                # åªæœ‰å½“ \end æ•°é‡ > \begin æ•°é‡æ—¶ï¼Œæ‰è®¤ä¸ºæ˜¯çœŸæ­£çš„ç¯å¢ƒç»“æŸ
                # è¿™æ ·å¯ä»¥æ­£ç¡®å¤„ç†åµŒå¥—çš„æƒ…å†µ
                if end_count > begin_count:
                    # æ£€æŸ¥è¿™è¡Œæ˜¯å¦æœ‰ \)
                    if not re.search(r'\\\)', line):
                        # åªåœ¨æœ€åä¸€ä¸ª \right. åæ·»åŠ  \)ï¼Œé¿å…ç ´ååµŒå¥—ç»“æ„
                        last_right_pos = line.rfind(r'\right.')
                        if last_right_pos != -1:
                            insert_pos = last_right_pos + 7  # len(r'\right.') = 7
                            line = line[:insert_pos] + r'\)' + line[insert_pos:]
                        else:
                            line = line + r'\)'
                        pending_close = max(0, pending_close - 1)
                    in_multiline_math = False

            # åœ¨æ¯è¡Œå†…æ£€æŸ¥å¹³è¡¡ï¼ˆä»…å¯¹éè·¨è¡Œç¯å¢ƒï¼‰
            if not in_multiline_math:
                opens = list(re.finditer(r'\\\(', line))
                closes = list(re.finditer(r'\\\)', line))
                open_count = len(opens)
                close_count = len(closes)

                if open_count > close_count:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è·¨è¡Œå¼€å§‹
                    if not re.search(r'\\begin\{(array|cases|matrix)', line):
                        line = line + r'\)' * (open_count - close_count)
                elif close_count > open_count:
                    diff = close_count - open_count
                    for _ in range(diff):
                        line = re.sub(r'^([^\\]*)\\\)', r'\1', line, count=1)

            processed_lines.append(line)

        return '\n'.join(processed_lines)
    
    def final_cleanup(self, text: str) -> str:
        """æœ€ç»ˆæ¸…ç†å’ŒéªŒè¯ï¼ˆå¢å¼ºç‰ˆ v1.9.2ï¼‰
        
        ğŸ†• v1.9.2 æ”¹è¿›:
        1. å…¨å±€å®šç•Œç¬¦å¹³è¡¡ä¿®å¤
        2. è¯†åˆ«å¹¶ä¿®å¤å­¤ç«‹çš„æ•°å­¦å†…å®¹
        """
        import re
        
        if not text:
            return text
        
        # 1. æ¸…ç†æ®‹ç•™çš„ $$
        text = re.sub(r'\$\$', '', text)
        
        # 2. æ¸…ç†ç©ºçš„æ•°å­¦æ¨¡å¼
        text = re.sub(r'\\\(\s*\\\)', '', text)
        
        # 3. æ¸…ç†è¿ç»­çš„å®šç•Œç¬¦
        for _ in range(3):
            text = re.sub(r'\\\(\\\(', r'\\(', text)
            text = re.sub(r'\\\)\\\)', r'\\)', text)
        
        # 4. ğŸ†• å…¨å±€å®šç•Œç¬¦å¹³è¡¡ä¿®å¤
        open_count = len(re.findall(r'\\\(', text))
        close_count = len(re.findall(r'\\\)', text))
        
        if open_count != close_count:
            diff = open_count - close_count
            # ğŸ†• v1.9.8: ç§»é™¤å†—ä½™è¾“å‡ºï¼Œä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤º
            
            # å°è¯•æ™ºèƒ½ä¿®å¤
            if diff > 0:
                # \( å¤šäº \)ï¼Œéœ€è¦æ·»åŠ  \)
                # æŸ¥æ‰¾å¯èƒ½ç¼ºå°‘ \) çš„ä½ç½®ï¼šè¡Œå°¾æœ‰ \( ä½†æ²¡æœ‰å¯¹åº”çš„ \)
                lines = text.split('\n')
                fixed_lines = []
                remaining_diff = diff
                
                for line in lines:
                    if remaining_diff > 0 and not line.strip().startswith('%'):
                        line_opens = len(re.findall(r'\\\(', line))
                        line_closes = len(re.findall(r'\\\)', line))
                        line_diff = line_opens - line_closes
                        
                        if line_diff > 0:
                            # åœ¨è¡Œå°¾æ·»åŠ ç¼ºå°‘çš„ \)
                            line = line + r'\)' * min(line_diff, remaining_diff)
                            remaining_diff -= line_diff
                    fixed_lines.append(line)
                
                text = '\n'.join(fixed_lines)
            elif diff < 0:
                # \) å¤šäº \(ï¼Œéœ€è¦ç§»é™¤å¤šä½™çš„ \) æˆ–æ·»åŠ  \(
                # æŸ¥æ‰¾è¡Œé¦–å­¤ç«‹çš„ \)
                lines = text.split('\n')
                fixed_lines = []
                remaining_diff = abs(diff)
                
                for line in lines:
                    if remaining_diff > 0 and not line.strip().startswith('%'):
                        # æ£€æŸ¥è¡Œé¦–æ˜¯å¦æœ‰å­¤ç«‹çš„ \)
                        while remaining_diff > 0 and re.match(r'^\s*\\\)', line):
                            line = re.sub(r'^(\s*)\\\)', r'\1', line, count=1)
                            remaining_diff -= 1
                    fixed_lines.append(line)
                
                text = '\n'.join(fixed_lines)
            
            # é‡æ–°éªŒè¯ï¼ˆé™é»˜å¤„ç†ï¼‰
            new_open = len(re.findall(r'\\\(', text))
            new_close = len(re.findall(r'\\\)', text))
        
        return text

    def fix_reversed_delimiters(self, text: str) -> str:
        r"""ä¿®å¤åå‘å®šç•Œç¬¦æ¨¡å¼ï¼ˆå¢å¼ºç‰ˆ v1.9.1ï¼‰

        ä¿®å¤æ¨¡å¼ï¼š
        1. \)ï¼šå…¬å¼\( â†’ \)ï¼š\(å…¬å¼\)ï¼ˆå†’å·åçš„å…¬å¼ç¼ºå°‘å¼€å¯ç¬¦ï¼‰
        2. \)åŠ¨è¯\( â†’ ä¿æŒä¸å˜ï¼ˆå¯èƒ½æ˜¯æ­£ç¡®çš„ï¼‰
        3. å­¤ç«‹çš„ \) åˆ é™¤
        """
        import re
        lines = text.split('\n')
        fixed_lines = []

        for line in lines:
            # è·³è¿‡æ³¨é‡Šè¡Œ
            if line.strip().startswith('%'):
                fixed_lines.append(line)
                continue

            # ğŸ†• æ¨¡å¼1ï¼šä¿®å¤å†’å·åçš„å…¬å¼ç¼ºå°‘ \( çš„æƒ…å†µ
            # åŒ¹é…: \)ï¼šå…¬å¼å†…å®¹\( æˆ– \)ï¼šå…¬å¼å†…å®¹ï¼ˆè¡Œå°¾/æ ‡ç‚¹ï¼‰
            # ä¾‹å¦‚: ç›´çº¿\(l_{1}\)ï¼š\sqrt{3}x - y = 0\) â†’ ç›´çº¿\(l_{1}\)ï¼š\(\sqrt{3}x - y = 0\)
            def fix_colon_pattern(match):
                close_paren = match.group(1)  # \)
                colon = match.group(2)  # ï¼šæˆ–:
                formula = match.group(3)  # å…¬å¼å†…å®¹
                terminator = match.group(4)  # \( æˆ–æ ‡ç‚¹æˆ–è¡Œå°¾

                # æ£€æŸ¥å…¬å¼å†…å®¹æ˜¯å¦åŒ…å«æ•°å­¦ç¬¦å·ï¼ˆç¡®è®¤æ˜¯æ•°å­¦å…¬å¼ï¼‰
                if re.search(r'[a-zA-Z_\^{}\\\d=+\-*/]', formula):
                    # æ˜¯æ•°å­¦å†…å®¹ï¼Œéœ€è¦æ·»åŠ  \(
                    if terminator == r'\(':
                        # åé¢å·²æœ‰ \(ï¼Œæ›¿æ¢ä¸º \)
                        return f'{close_paren}{colon}\\({formula}\\)'
                    elif terminator in ['ï¼Œ', 'ã€‚', 'ï¼›', 'ã€', 'ï¼‰', '\n', '']:
                        # åé¢æ˜¯æ ‡ç‚¹æˆ–è¡Œå°¾ï¼Œæ·»åŠ  \(\)
                        return f'{close_paren}{colon}\\({formula}\\){terminator}'
                    else:
                        return match.group(0)
                else:
                    # ä¸æ˜¯æ•°å­¦å†…å®¹ï¼Œä¿æŒåŸæ ·
                    return match.group(0)

            # åŒ¹é…å†’å·æ¨¡å¼ï¼š\)ï¼š[å…¬å¼å†…å®¹][\(æˆ–æ ‡ç‚¹æˆ–è¡Œå°¾]
            pattern_colon = re.compile(
                r'(\\\))' +                           # æ•è·ç»„1: \)
                r'([ï¼š:])' +                          # æ•è·ç»„2: ä¸­æ–‡æˆ–è‹±æ–‡å†’å·
                r'([^\\(ï¼‰\n]{1,100}?)' +             # æ•è·ç»„3: å…¬å¼å†…å®¹ï¼ˆéè´ªå©ªï¼Œä¸åŒ…å«\(å’Œï¼‰ï¼‰
                r'(\\\(|[ï¼Œã€‚ï¼›ã€ï¼‰]|\n|$)'            # æ•è·ç»„4: \( æˆ–æ ‡ç‚¹æˆ–è¡Œå°¾
            )
            line = pattern_colon.sub(fix_colon_pattern, line)

            # ğŸ†• æ¨¡å¼2ï¼šé€è¡Œæ£€æŸ¥å®šç•Œç¬¦å¹³è¡¡ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
            opens = [(m.start(), r'\(') for m in re.finditer(r'\\\(', line)]
            closes = [(m.start(), r'\)') for m in re.finditer(r'\\\)', line)]

            all_delims = sorted(opens + closes, key=lambda x: x[0])

            depth = 0
            needs_fix = False
            for pos, delim in all_delims:
                if delim == r'\(':
                    depth += 1
                else:
                    depth -= 1
                    if depth < 0:
                        needs_fix = True
                        break

            if needs_fix:
                # ä¿®å¤ç­–ç•¥: ç§»é™¤è¡Œé¦–çš„å­¤ç«‹ \)
                line = re.sub(r'^([^\\\(]*?)\\\)', r'\1', line)

            fixed_lines.append(line)

        return '\n'.join(fixed_lines)

    def process(self, text: str) -> str:
        # é¢„å¤„ç†ï¼šä¿æŠ¤ä¸­æ–‡æ‹¬å·ï¼Œé¿å…ä¸æ•°å­¦æ‹¬å·æ··æ·†
        chinese_paren_map = {
            'ï¼ˆ': '@@ZH_PAREN_OPEN@@',
            'ï¼‰': '@@ZH_PAREN_CLOSE@@',
            'ã€': '@@ZH_BRACKET_OPEN@@',
            'ã€‘': '@@ZH_BRACKET_CLOSE@@',
        }
        for char, placeholder in chinese_paren_map.items():
            text = text.replace(char, placeholder)

        # ğŸ†• P0-001 & P1-005: åœ¨é¢„å¤„ç†å¤šè¡Œæ•°å­¦ä¹‹å‰ä¿®å¤é›†åˆå®šä¹‰å’ŒOCRé”™è¯¯
        text = fix_broken_set_definitions(text)
        text = fix_ocr_specific_errors(text)
        
        # å…ˆé¢„å¤„ç†å¤šè¡Œæ•°å­¦å—
        text = self.preprocess_multiline_math(text)
        # ç„¶åå¤„ç†å‰©ä½™çš„å•è¡Œå…¬å¼
        tokens = self.tokenize(text)
        out = []
        i = 0
        math_depth = 0  # è·Ÿè¸ªæ•°å­¦æ¨¡å¼æ·±åº¦

        while i < len(tokens):
            t_type, val, pos = tokens[i]

            # ğŸ”¥ v1.8.3ï¼šæ™ºèƒ½å¤„ç† \right. è¾¹ç•Œ
            if t_type == TokenType.RIGHT_BOUNDARY:
                # æ£€æŸ¥æ˜¯å¦åœ¨æ•°å­¦æ¨¡å¼å†…ï¼ˆæœ‰æœªé—­åˆçš„ \(ï¼‰
                if math_depth > 0:
                    out.append(r'\right.\)')
                    math_depth -= 1
                else:
                    # ä¸åœ¨æ•°å­¦æ¨¡å¼å†…ï¼Œä¿æŒåŸæ ·ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ \right.ï¼‰
                    out.append(r'\right.')
                i += 1
                continue
            if t_type == TokenType.DOLLAR_DOUBLE:
                # æ”¶é›†ç›´åˆ°ä¸‹ä¸€ä¸ª $$ æˆ– RIGHT_BOUNDARY
                i += 1
                buf = []
                while i < len(tokens):
                    tt, tv, _ = tokens[i]
                    if tt == TokenType.DOLLAR_DOUBLE:
                        i += 1
                        break
                    # ğŸ†• v1.9.4ï¼šé‡åˆ° DOLLAR_SINGLEï¼Œè§†ä¸º $$ çš„é”™è¯¯ç»“æŸç¬¦ï¼ˆ$$...$æ¨¡å¼ï¼‰
                    # å°† $ ä½œä¸ºç»“æŸç¬¦ï¼Œä¸æ”¶é›†åˆ° buf ä¸­
                    if tt == TokenType.DOLLAR_SINGLE:
                        i += 1
                        break
                    # ğŸ†• v1.9.3ï¼šé‡åˆ° RIGHT_BOUNDARYï¼Œè¾“å‡ºå®ƒç„¶åæ£€æŸ¥ä¸‹ä¸€ä¸ªæ˜¯å¦æ˜¯ $$
                    if tt == TokenType.RIGHT_BOUNDARY:
                        buf.append(r'\right.')
                        i += 1
                        # æ£€æŸ¥ä¸‹ä¸€ä¸ª token æ˜¯å¦æ˜¯ $$ ç»“æŸç¬¦
                        if i < len(tokens) and tokens[i][0] == TokenType.DOLLAR_DOUBLE:
                            i += 1  # è·³è¿‡ç»“æŸçš„ $$
                            break
                        # ä¹Ÿæ£€æŸ¥ DOLLAR_SINGLEï¼ˆ$$...\right.$æ¨¡å¼ï¼‰
                        if i < len(tokens) and tokens[i][0] == TokenType.DOLLAR_SINGLE:
                            i += 1
                            break
                        continue
                    buf.append(tv)
                    i += 1
                out.append(r'\(' + ''.join(buf).strip() + r'\)')
                continue

            if t_type == TokenType.DOLLAR_SINGLE:
                i += 1
                buf = []
                while i < len(tokens):
                    tt, tv, _ = tokens[i]
                    if tt == TokenType.DOLLAR_SINGLE:
                        i += 1
                        break
                    # ç¦æ­¢è·¨è¡Œçš„å•ç¾å…ƒå»¶ä¼¸
                    if '\n' in tv:
                        out.append('$')
                        out.extend(buf)
                        break
                    buf.append(tv)
                    i += 1
                if buf:
                    out.append(r'\(' + ''.join(buf) + r'\)')
                continue

            if t_type == TokenType.LATEX_OPEN:
                out.append(val)
                math_depth += 1
                i += 1
                continue

            if t_type == TokenType.LATEX_CLOSE:
                out.append(val)
                math_depth = max(0, math_depth - 1)
                i += 1
                continue
            out.append(val)
            i += 1

        result = ''.join(out)

        # åå¤„ç†æ­¥éª¤ï¼ˆæŒ‰é¡ºåºæ‰§è¡Œï¼‰
        result = self.fix_malformed_patterns(result)
        result = self.normalize_punctuation_in_math(result)
        result = self.split_colon_from_math(result)
        result = self.fix_math_symbol_chinese_boundary(result)
        result = self.split_chinese_from_math(result)
        result = self.balance_delimiters(result)
        result = self.final_cleanup(result)

        # ä¿®å¤åå‘å®šç•Œç¬¦
        result = self.fix_reversed_delimiters(result)

        # åå¤„ç†ï¼šæ¢å¤ä¸­æ–‡æ‹¬å·
        for char, placeholder in chinese_paren_map.items():
            result = result.replace(placeholder, char)

        return result


# å•ä¾‹å®ä¾‹ä¾›å…¨å±€è°ƒç”¨


math_sm = MathStateMachine()


def fix_array_boundaries(text: str) -> str:
    r"""ä¿®å¤ array ç¯å¢ƒçš„è¾¹ç•Œç¬¦é”™è¯¯
    
    ğŸ†• v1.6 P0 ä¿®å¤ï¼šä¿®æ­£ \right.\\) â†’ \right.\)
    """
    # ä¿®æ­£ \right. åçš„åŒåæ–œæ 
    text = re.sub(r'\\right\.\\\\\)', r'\\right.\\)', text)
    
    # ä¿®æ­£å…¶ä»–è¾¹ç•Œç¬¦
    text = re.sub(r'\\right\)\\\\\)', r'\\right)\\)', text)
    text = re.sub(r'\\right\]\\\\\)', r'\\right]\\)', text)
    text = re.sub(r'\\right\}\\\\\)', r'\\right}\\)', text)
    
    # åŒæ ·ä¿®æ­£ \left çš„æƒ…å†µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    text = re.sub(r'\\\\\(\\left', r'\\(\\left', text)
    
    return text




def fix_broken_set_definitions(text: str) -> str:
    r"""ä¿®å¤è¢« $$ æˆªæ–­çš„é›†åˆå®šä¹‰ (P0-001)
    
    æ£€æµ‹æ¨¡å¼ï¼š\right.\ $$ä¸­æ–‡$$\left. \
    æ›¿æ¢ä¸ºï¼š\right.\text{ä¸­æ–‡}\left.
    
    ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼š\right.\ $$æ˜¯è´¨æ•°$$\left. \
        è¾“å‡ºï¼š\right.\text{ æ˜¯è´¨æ•° }\left.
    """
    import re
    
    if not text:
        return text
    
    # æ¨¡å¼1: \right.\ $$ä¸­æ–‡$$\left. \ï¼ˆé›†åˆæ¡ä»¶è¢«æˆªæ–­ï¼‰
    pattern1 = re.compile(
        r'(\\right\.)\s*\\\s*\$\$([^$]+)\$\$\s*\\left\.\s*\\',
        re.DOTALL
    )
    text = pattern1.sub(r'\1\\text{\2}\\left.', text)
    
    # æ¨¡å¼2: \right.\ $$ä¸­æ–‡ï¼ˆè¡Œå°¾æˆªæ–­ï¼‰
    # ğŸ”§ v1.9.5ï¼šå¢åŠ é™åˆ¶æ¡ä»¶ï¼Œé¿å…åŒ¹é… \right.\ $$ï¼Œ\n è¿™ç§æ ‡ç‚¹åæ¢è¡Œçš„æ¨¡å¼
    # è¦æ±‚ä¸­æ–‡å†…å®¹è‡³å°‘åŒ…å«ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œè€Œä¸ä»…ä»…æ˜¯æ ‡ç‚¹
    pattern2 = re.compile(
        r'(\\right\.)\s*\\\s*\$\$([\u4e00-\u9fff][^$]*)$',
        re.MULTILINE
    )
    text = pattern2.sub(r'\1\\text{\2}', text)
    
    # æ¨¡å¼3: $$æˆ–$$\left. \ï¼ˆ"æˆ–"å­—è¢«åˆ†ç¦»ï¼‰
    pattern3 = re.compile(
        r'\$\$(æˆ–|ä¸”|å’Œ|å³)\$\$\\left\.\s*\\',
        re.DOTALL
    )
    text = pattern3.sub(r'\\text{ \1 }\\left.', text)
    
    return text




def fix_ocr_specific_errors(text: str) -> str:
    r"""ä¿®å¤ OCR ç‰¹æœ‰çš„è¯†åˆ«é”™è¯¯ (P1-005)
    
    å¤„ç†ï¼š
    1. ç§»é™¤ \boxed{}ï¼Œä¿ç•™å†…å®¹
    2. æ¸…ç†è¿ç»­ç©ºæ ¼è½¬ä¹‰ \  \  \ 
    3. ä¿®å¤ \left| ä¸º \midï¼ˆåœ¨é›†åˆå®šä¹‰ä¸­ï¼‰
    
    ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼šB = \left\{ \boxed{x} - 3 < x < 1 \right\}
        è¾“å‡ºï¼šB = \left\{ x \mid -3 < x < 1 \right\}
    """
    import re
    
    if not text:
        return text
    
    # 1. ç§»é™¤ \boxed{}ï¼Œä¿ç•™å†…å®¹
    text = re.sub(r'\\boxed\{([^}]*)\}', r'\1', text)
    
    # 2. æ¸…ç†è¿ç»­ç©ºæ ¼è½¬ä¹‰ \  \  \ 
    text = re.sub(r'(\\ ){2,}', r' ', text)
    
    # 3. ä¿®å¤ \left| ä¸º \midï¼ˆåœ¨é›†åˆå®šä¹‰ä¸­ï¼‰
    # åŒ¹é… \left\{ ... \left| ... \right. ... \right\}
    def fix_set_bar(match):
        content = match.group(0)
        # å°†é›†åˆæ¡ä»¶ä¸­çš„ \left| æ›¿æ¢ä¸º \mid
        content = re.sub(r'\\left\|', r'\\mid ', content)
        # ç§»é™¤å¯¹åº”çš„ \right.ï¼ˆå¦‚æœæœ‰ï¼‰
        content = re.sub(r'\\mid\s*([^}]*?)\\right\.', r'\\mid \1', content)
        return content
    
    text = re.sub(
        r'\\left\\{[^}]*?\\left\|[^}]*?\\right\\}',
        fix_set_bar,
        text,
        flags=re.DOTALL
    )
    
    return text




def fix_right_boundary_errors(text: str) -> str:
    """ä¿®å¤ \\right. è¾¹ç•Œé”™è¯¯ - å¢å¼ºç‰ˆ
    
    å¤„ç†ä»¥ä¸‹ç•¸å½¢æ¨¡å¼ï¼š
    1. \\right.\\ $$ â†’ \\right.\\)  (åæ–œæ +ç©ºæ ¼+åŒç¾å…ƒ)
    2. \\right.\\\\ $$ â†’ \\right.\\)  (åŒåæ–œæ +åŒç¾å…ƒ)
    3. \\right. $$ â†’ \\right.\\)  (ç©ºæ ¼+åŒç¾å…ƒ)
    4. \\right.ä¸­æ–‡ â†’ \\right.\\)ä¸­æ–‡  (ç›´æ¥è·Ÿä¸­æ–‡)
    """
    import re
    
    if not text:
        return text
    
    # æ¨¡å¼1: \right.\ $$ (åæ–œæ +ç©ºæ ¼+åŒç¾å…ƒ) - æœ€å¸¸è§çš„OCRé”™è¯¯
    text = re.sub(r'\\right\.\\\s\$\$', r'\\right.\\)', text)
    
    # æ¨¡å¼2: \right.\\ $$ (åŒåæ–œæ +å¯é€‰ç©ºæ ¼+åŒç¾å…ƒ)
    text = re.sub(r'\\right\.\\\\\s*\$\$', r'\\right.\\)', text)
    
    # æ¨¡å¼3: \right. $$ (ä¸€ä¸ªæˆ–å¤šä¸ªç©ºæ ¼+åŒç¾å…ƒ)
    text = re.sub(r'\\right\.\s+\$\$', r'\\right.\\)', text)
    
    # æ¨¡å¼4: \right.$$ (ç›´æ¥è·ŸåŒç¾å…ƒï¼Œæ— ç©ºæ ¼)
    text = re.sub(r'\\right\.\$\$', r'\\right.\\)', text)
    
    # æ¨¡å¼5: \right. åç›´æ¥è·Ÿä¸­æ–‡æ ‡ç‚¹ï¼ˆç¼ºå°‘ \)ï¼‰
    text = re.sub(r'(\\right\.)\s*([ï¼Œã€‚ï¼›ï¼šã€ï¼ï¼Ÿ])', r'\1\\)\2', text)
    
    # æ¨¡å¼6: \right. åç›´æ¥è·Ÿä¸­æ–‡æ–‡å­—ï¼ˆç¼ºå°‘ \)ï¼‰
    text = re.sub(r'(\\right\.)\s*([\u4e00-\u9fa5])', r'\1\\)\2', text)
    
    return text




def fix_unmatched_close_delimiters(text: str) -> str:
    r"""ä¿®å¤æœªåŒ¹é…çš„é—­åˆå®šç•Œç¬¦ - ä½¿ç”¨æ ˆç®—æ³•ï¼ˆè·¨è¡Œå¤„ç†ï¼‰

    ğŸ†• v1.9.8: é‡å‘½åè‡ª fix_reversed_delimitersï¼Œé¿å…ä¸ç±»æ–¹æ³•åŒåæ··æ·†

    æ£€æµ‹æ²¡æœ‰åŒ¹é…çš„ \) å¹¶åˆ é™¤å®ƒä»¬ã€‚

    ğŸ†• v1.9.4: æ”¹ä¸ºå…¨æ–‡è·¨è¡Œå¤„ç†ï¼Œè€Œéé€è¡Œå¤„ç†ï¼Œä»¥æ­£ç¡®å¤„ç†å¤šè¡Œæ•°å­¦å—å¦‚ï¼š
        è”ç«‹\(\left\{ \begin{array}{r}
        x = my + \frac{3}{2} \\
        y^{2} = 6x
        \end{array} \right.\)

    é€è¡Œå¤„ç†ä¼šé”™è¯¯åœ°åœ¨ç¬¬ä¸€è¡Œæœ«å°¾æ·»åŠ  \)ï¼Œå› ä¸ºè¯¥è¡Œçš„ \( åœ¨åç»­è¡Œæ‰é—­åˆã€‚
    """
    import re
    
    if not text:
        return text
    
    # å…¨æ–‡å¤„ç†ï¼šä½¿ç”¨æ ˆæ£€æµ‹ä¸åŒ¹é…çš„å®šç•Œç¬¦
    stack = []  # å­˜å‚¨ \( çš„ä½ç½®
    unmatched_close = []  # å­˜å‚¨æ²¡æœ‰åŒ¹é…çš„ \) çš„ä½ç½®
    
    # æ‰¾åˆ°æ‰€æœ‰å®šç•Œç¬¦ï¼ˆæ’é™¤æ³¨é‡Šè¡Œä¸­çš„ï¼‰
    lines = text.split('\n')
    comment_ranges = []  # è®°å½•æ³¨é‡Šè¡Œçš„å­—ç¬¦èŒƒå›´
    pos = 0
    for line in lines:
        if line.strip().startswith('%'):
            comment_ranges.append((pos, pos + len(line)))
        pos += len(line) + 1  # +1 for \n
    
    def is_in_comment(position):
        for start, end in comment_ranges:
            if start <= position < end:
                return True
        return False
    
    for m in re.finditer(r'\\\(|\\\)', text):
        if is_in_comment(m.start()):
            continue
        delim = m.group(0)
        pos = m.start()
        
        if delim == r'\(':
            stack.append(pos)
        else:  # \)
            if stack:
                stack.pop()  # æ‰¾åˆ°åŒ¹é…
            else:
                unmatched_close.append(pos)  # æ²¡æœ‰åŒ¹é…çš„ \)
    
    # å¦‚æœå­˜åœ¨ä¸åŒ¹é…çš„å®šç•Œç¬¦ï¼Œéœ€è¦ä¿®å¤
    if not unmatched_close and not stack:
        return text  # å·²ç»å¹³è¡¡ï¼Œæ— éœ€ä¿®æ”¹
    
    # åˆ é™¤æ²¡æœ‰åŒ¹é…çš„ \)ï¼ˆä»åå¾€å‰åˆ é™¤ä»¥ä¿æŒä½ç½®æ­£ç¡®ï¼‰
    result = text
    if unmatched_close:
        text_chars = list(result)
        for pos in reversed(unmatched_close):
            # åˆ é™¤ \) (ä¸¤ä¸ªå­—ç¬¦)
            if pos + 1 < len(text_chars):
                del text_chars[pos:pos+2]
        result = ''.join(text_chars)

    # å¦‚æœä»æœ‰æœªåŒ¹é…çš„ \(ï¼ˆå¼€å¤šé—­å°‘ï¼‰ï¼Œè¿½åŠ å¯¹åº”æ•°é‡çš„æ”¶å°¾ \)
    # åªåœ¨å…¨æ–‡çº§åˆ«å¤„ç†ï¼Œé¿å…é€è¡Œè¡¥é½å¸¦æ¥çš„è¯¯ä¿®å¤
    if stack:
        extra_closes = []
        # ç¬¬ä¸€ä¸ªç›´æ¥è¡¥ä¸€ä¸ª \)
        extra_closes.append('\\)')
        # å…¶ä½™çš„ç”¨æ³¨é‡Šåˆ†éš”ï¼Œé¿å…å‡ºç° \)\) è¢«åˆ¤å®šä¸ºâ€œåŒé‡åŒ…è£¹â€
        for _ in range(len(stack) - 1):
            extra_closes.append('% auto-close added by fix_unmatched_close_delimiters\n\\)')
        result = result + ''.join(extra_closes)

    return result




def balance_array_and_cases_env(text: str) -> str:
    """ğŸ†• v1.8.6ï¼šåå¤„ç† - åˆ é™¤æ˜æ˜¾å¤šä½™çš„ \\end{array}/\\end{cases}

    åªåœ¨æ²¡æœ‰åŒ¹é… \\begin æ—¶ä¸¢å¼ƒ \\endï¼Œä¸è‡ªåŠ¨ç”Ÿæˆæ–°çš„ \\beginã€‚
    ä½¿ç”¨æ ˆåŒ¹é…ç®—æ³•ï¼Œç¡®ä¿ array/cases ç¯å¢ƒå¹³è¡¡ã€‚

    ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼š\\end{array} \\right.\\)ï¼Œåˆ™ï¼ˆæ— å¯¹åº”çš„ \\begin{array}ï¼‰
        è¾“å‡ºï¼š\\right.\\)ï¼Œåˆ™ï¼ˆä¸¢å¼ƒå¤šä½™çš„ \\end{array}ï¼‰
    """
    if not text:
        return text

    pattern = re.compile(r'\\(begin|end)\{(array|cases)\}')
    out_parts = []
    stack = []
    last = 0

    for m in pattern.finditer(text):
        out_parts.append(text[last:m.start()])
        kind, env = m.group(1), m.group(2)
        token = m.group(0)

        if kind == 'begin':
            stack.append(env)
            out_parts.append(token)
        else:  # end
            if stack and env in stack:
                # ä»æ ˆå°¾æ‰¾åŒ¹é…çš„ begin
                idx = len(stack) - 1 - stack[::-1].index(env)
                stack.pop(idx)
                out_parts.append(token)
            else:
                # æ²¡æœ‰åŒ¹é…çš„ beginï¼Œè¯´æ˜æ˜¯å¤šä½™çš„ \end{env}ï¼Œç›´æ¥ä¸¢å¼ƒ
                # é™é»˜å¤„ç†æœªåŒ¹é…çš„ token
                pass

        last = m.end()

    out_parts.append(text[last:])
    return ''.join(out_parts)




def fix_trig_function_spacing(text: str) -> str:
    r"""ğŸ†• v1.9.6ï¼šä¿®å¤ä¸‰è§’å‡½æ•°å’Œå¯¹æ•°å‡½æ•°åç¼ºå°‘ç©ºæ ¼çš„é—®é¢˜
    
    é—®é¢˜æ¨¡å¼ï¼š
    - \sinx â†’ \sin x
    - \cosB â†’ \cos B
    - \lnt â†’ \ln t
    - \sinwt â†’ \sin(\omega t) æˆ– \sin wtï¼ˆç‰¹æ®Šå¤„ç† wt/Ï‰t æ ¼å¼ï¼‰
    
    ä¿å®ˆå¤„ç†ï¼šåªä¿®å¤åé¢ç´§è·Ÿå­—æ¯/å˜é‡çš„æƒ…å†µ
    """
    import re
    
    # å®šä¹‰éœ€è¦å¤„ç†çš„å‡½æ•°å
    trig_funcs = ['sin', 'cos', 'tan', 'cot', 'sec', 'csc', 'arcsin', 'arccos', 'arctan',
                  'sinh', 'cosh', 'tanh', 'ln', 'log', 'lg', 'exp']
    
    for func in trig_funcs:
        # ç‰¹æ®Šå¤„ç†ï¼š\sinwt, \coswt ç­‰ â†’ \sin(\omega t), \cos(\omega t)
        # è¿™æ˜¯ç‰©ç†/ä¿¡å·å¤„ç†ä¸­å¸¸è§çš„è¡¨è¾¾å¼
        text = re.sub(rf'\\{func}wt\b', rf'\\{func}(\\omega t)', text)
        text = re.sub(rf'\\{func}Ï‰t\b', rf'\\{func}(\\omega t)', text)
        
        # åŒ¹é… \func åç´§è·Ÿå­—æ¯ï¼ˆé { æˆ–ç©ºæ ¼çš„æƒ…å†µï¼‰
        # ä¾‹å¦‚ \sinx â†’ \sin x, \cosB â†’ \cos B
        # åªå¤„ç†å•ä¸ªå­—æ¯çš„æƒ…å†µï¼Œé¿å…è¯¯æ”¹å¤æ‚è¡¨è¾¾å¼
        pattern = rf'\\{func}([A-Za-z])(?![a-zA-Z])'
        text = re.sub(pattern, rf'\\{func} \1', text)
    
    return text




def fix_greek_letter_spacing(text: str) -> str:
    r"""ğŸ†• v1.9.9ï¼šä¿®å¤å¸Œè…Šå­—æ¯ä¸å˜é‡è¿å†™é—®é¢˜
    
    é—®é¢˜æ¥æºï¼š
    - OCR æˆ– Pandoc å°†å¸Œè…Šå­—æ¯ä¸å˜é‡è¿å†™ï¼Œå¦‚ \pir åº”è¯¥æ˜¯ \pi r
    - LaTeX ä¼šå°† \pir è§£é‡Šä¸ºæœªå®šä¹‰çš„å‘½ä»¤
    
    ä¿å®ˆç­–ç•¥ï¼š
    - åªå¤„ç†å¸¸è§çš„å¸Œè…Šå­—æ¯åç›´æ¥è·Ÿå°å†™è‹±æ–‡å­—æ¯çš„æƒ…å†µ
    - ä¸å¤„ç† \alpha_1 ç­‰ä¸‹æ ‡æƒ…å†µï¼ˆè¿™æ˜¯æ­£ç¡®çš„ï¼‰
    - ä»…æ·»åŠ ç©ºæ ¼åˆ†éš”ï¼Œä¸æ”¹å˜å…¶ä»–å†…å®¹
    
    å¸¸è§é—®é¢˜æ¨¡å¼ï¼š
    - \pir â†’ \pi r
    - \thetar â†’ \theta r
    
    æ³¨æ„ï¼šè¿™æ˜¯ä¿å®ˆä¿®å¤ï¼Œåªå¤„ç†æ˜ç¡®çš„è¿å†™æ¨¡å¼
    """
    import re
    
    # ğŸ†• v1.9.9: P2-10 è¡¥å……å®Œæ•´å¸Œè…Šå­—æ¯åˆ—è¡¨
    greek_letters = [
        # å°å†™å¸Œè…Šå­—æ¯
        'alpha', 'beta', 'gamma', 'delta', 'epsilon', 'varepsilon',
        'zeta', 'eta', 'theta', 'vartheta', 'iota', 'kappa', 'varkappa',
        'lambda', 'mu', 'nu', 'xi', 'pi', 'varpi',
        'rho', 'varrho', 'sigma', 'varsigma', 'tau', 'upsilon',
        'phi', 'varphi', 'chi', 'psi', 'omega',
        # å¤§å†™å¸Œè…Šå­—æ¯ï¼ˆLaTeX ä¸­åªæœ‰éƒ¨åˆ†å¤§å†™æœ‰ä¸“é—¨å‘½ä»¤ï¼‰
        'Gamma', 'Delta', 'Theta', 'Lambda', 'Xi', 'Pi',
        'Sigma', 'Upsilon', 'Phi', 'Psi', 'Omega',
    ]
    
    for letter in greek_letters:
        # æ¨¡å¼ï¼š\greek + å°å†™å­—æ¯ï¼ˆä¸æ˜¯ä¸‹æ ‡å¼€å¤´ï¼‰
        # ä¾‹å¦‚ï¼š\pir â†’ \pi rï¼Œä½†ä¸æ”¹å˜ \pi_r æˆ– \pi{...}
        pattern = rf'(\\{letter})([a-z])(?![_{{])'
        text = re.sub(pattern, r'\1 \2', text)
    
    return text




def fix_bold_math_symbols(text: str) -> str:
    r"""ğŸ†• v1.9.9ï¼šä¿®å¤ Pandoc ç²—ä½“åŒ…è£¹æ•°å­¦ç¬¦å·çš„é—®é¢˜
    
    é—®é¢˜æ¥æºï¼š
    - Word ä¸­çš„ç²—ä½“å­—æ¯ï¼ˆå¦‚ **R** è¡¨ç¤ºå®æ•°é›†ï¼‰
    - Pandoc è½¬æ¢ä¸º *\(R\)* æ ¼å¼
    - è¿™åœ¨ LaTeX ä¸­ä¼šå¯¼è‡´æ¸²æŸ“é—®é¢˜
    
    ä¿å®ˆç­–ç•¥ï¼š
    - åªå¤„ç† *\(X\)* æ ¼å¼ï¼Œå…¶ä¸­ X æ˜¯å•ä¸ªå¤§å†™å­—æ¯
    - è½¬æ¢ä¸º \(\mathbf{X}\)
    - å¸¸è§äºæ•°å­¦é›†åˆç¬¦å·ï¼šRï¼ˆå®æ•°ï¼‰ã€Zï¼ˆæ•´æ•°ï¼‰ã€Nï¼ˆè‡ªç„¶æ•°ï¼‰ç­‰
    
    ä¾‹å¦‚ï¼š
    - *\(R\)* â†’ \(\mathbf{R}\)
    - *\(Z\)* â†’ \(\mathbf{Z}\)
    """
    import re
    
    # æ¨¡å¼ï¼š*\(å•ä¸ªå¤§å†™å­—æ¯\)* â†’ \(\mathbf{å­—æ¯}\)
    # åªåŒ¹é…å•ä¸ªå¤§å†™å­—æ¯ï¼Œé¿å…è¯¯ä¼¤å…¶ä»–ç²—ä½“æ•°å­¦è¡¨è¾¾å¼
    text = re.sub(r'\*\\\(([A-Z])\\\)\*', r'\\(\\mathbf{\1}\\)', text)
    
    return text




def fix_overset_arrow_vectors(text: str) -> str:
    r"""ğŸ†• v1.9.10ï¼šä¿®å¤ \overset{arrow}{...} å‘é‡ç¬¦å·é”™è¯¯
    
    é—®é¢˜æ¥æºï¼š
    - Pandoc æˆ– OCR å°†å‘é‡ç¬¦å·è½¬æ¢ä¸º \overset{arrow}{a} æˆ– \overset{\rightarrow}{a}
    - è¿™ä¸æ˜¯æœ‰æ•ˆçš„ LaTeX å‘½ä»¤ï¼Œä¼šå¯¼è‡´ç¼–è¯‘å¤±è´¥
    
    ä¿å®ˆç­–ç•¥ï¼š
    - åªå¤„ç†æ˜ç¡®çš„ \overset{arrow}{...} å’Œ \overset{\rightarrow}{...} æ¨¡å¼
    - è½¬æ¢ä¸ºæ ‡å‡†çš„ \vec{...} ç¬¦å·
    - ä¸å½±å“å…¶ä»– \overset ç”¨æ³•ï¼ˆå¦‚ \overset{def}{=}ï¼‰
    
    å¸¸è§é—®é¢˜æ¨¡å¼ï¼š
    - \overset{arrow}{a} â†’ \vec{a}
    - \overset{\rightarrow}{a} â†’ \vec{a}
    - \overset{arrow}{AB} â†’ \overrightarrow{AB}ï¼ˆå¤šå­—ç¬¦ç”¨ overrightarrowï¼‰
    
    æ³¨æ„ï¼šè¿™æ˜¯ä¿å®ˆä¿®å¤ï¼Œåªå¤„ç†å‘é‡ç›¸å…³çš„ overset æ¨¡å¼
    """
    import re
    
    # æ¨¡å¼1ï¼š\overset{arrow}{å•ä¸ªå­—æ¯} â†’ \vec{å­—æ¯}
    # åŒ¹é… \overset{arrow}{a} æˆ– \overset{arrow}{x} ç­‰å•å­—ç¬¦
    text = re.sub(
        r'\\overset\{arrow\}\{([a-zA-Z])\}',
        r'\\vec{\1}',
        text
    )
    
    # æ¨¡å¼2ï¼š\overset{\rightarrow}{å•ä¸ªå­—æ¯} â†’ \vec{å­—æ¯}
    text = re.sub(
        r'\\overset\{\\rightarrow\}\{([a-zA-Z])\}',
        r'\\vec{\1}',
        text
    )
    
    # æ¨¡å¼3ï¼š\overset{arrow}{å¤šå­—ç¬¦} â†’ \overrightarrow{å¤šå­—ç¬¦}
    # åŒ¹é… \overset{arrow}{AB} æˆ– \overset{arrow}{PQ} ç­‰å¤šå­—ç¬¦ï¼ˆ2ä¸ªæˆ–æ›´å¤šï¼‰
    text = re.sub(
        r'\\overset\{arrow\}\{([a-zA-Z_][a-zA-Z0-9_]+)\}',
        r'\\overrightarrow{\1}',
        text
    )
    
    # æ¨¡å¼4ï¼š\overset{\rightarrow}{å¤šå­—ç¬¦} â†’ \overrightarrow{å¤šå­—ç¬¦}
    text = re.sub(
        r'\\overset\{\\rightarrow\}\{([a-zA-Z_][a-zA-Z0-9_]+)\}',
        r'\\overrightarrow{\1}',
        text
    )
    
    return text




def fix_specific_reversed_pairs(text: str) -> str:
    r"""ğŸ†• v1.8.7ï¼šæçª„è‡ªåŠ¨ä¿®å¤ç‰¹å®šåå‘æ•°å­¦å®šç•Œç¬¦æ¨¡å¼

    ä»…é’ˆå¯¹ç²¾ç¡®åŒ¹é…çš„å·²çŸ¥é”™è¯¯æ¨¡å¼ï¼š
    - æ¨¡å¼ A: æ±‚ç‚¹\)X_{2}\(æ‰€æœ‰å¯èƒ½çš„åæ ‡ â†’ æ±‚ç‚¹\(X_{2}\)æ‰€æœ‰å¯èƒ½çš„åæ ‡
    - æ¨¡å¼ B: å…¶ä¸­\)x_{i} â†’ å…¶ä¸­ x_{i}ï¼ˆåˆ é™¤ä¸åŒ¹é…çš„ \)ï¼‰

    å®‰å…¨æ€§ï¼šåªé’ˆå¯¹ç²¾ç¡®åŒ¹é…çš„æ¨¡å¼ï¼Œä¸å½±å“å…¶ä»–å†…å®¹
    """
    if not text:
        return text

    # æ¨¡å¼ A: æ±‚ç‚¹\)X_{2}\(æ‰€æœ‰å¯èƒ½çš„åæ ‡ â†’ æ±‚ç‚¹\(X_{2}\)æ‰€æœ‰å¯èƒ½çš„åæ ‡
    # ç²¾ç¡®åŒ¹é…ï¼š\) + å­—æ¯/æ•°å­—/ä¸‹åˆ’çº¿ + \( â†’ \( + å­—æ¯/æ•°å­—/ä¸‹åˆ’çº¿ + \)
    pattern_a = re.compile(r'\\\)([A-Za-z0-9_{}]+)\\\(')
    text = pattern_a.sub(r'\(\1\)', text)

    # æ¨¡å¼ B: å…¶ä¸­\)x_{i} â†’ å…¶ä¸­ x_{i}ï¼ˆåˆ é™¤ä¸åŒ¹é…çš„ \)ï¼‰
    # ç²¾ç¡®åŒ¹é…ï¼š\) + ç©ºæ ¼ + å­—æ¯/æ•°å­—ï¼ˆè¡Œå°¾æˆ–åç»­æ—  \(ï¼‰
    pattern_b = re.compile(r'\\\)\s+([a-z][a-z_0-9{}]*(?![^\n]*\\\())')
    text = pattern_b.sub(r' \1', text)

    return text




def fix_simple_reversed_inline_pairs(text: str) -> str:
    r"""ğŸ†• v1.8.8 / v1.9.3ï¼šæåº¦ä¿å®ˆçš„åå‘å®šç•Œç¬¦è‡ªåŠ¨ä¿®å¤

    åªä¿®å¤çœŸæ­£çš„åå‘å®šç•Œç¬¦ï¼šå³ \) ä¹‹å‰æ²¡æœ‰åŒ¹é…çš„ \(ï¼Œä¸” \( ä¹‹åæ²¡æœ‰åŒ¹é…çš„ \)ã€‚

    v1.9.3 ä¿®å¤ï¼šä¸å†é”™è¯¯åœ°åˆå¹¶ä¸¤ä¸ªç‹¬ç«‹çš„æ­£ç¡®æ•°å­¦å—ï¼Œä¾‹å¦‚ï¼š
    - æ­£ç¡®ä¿ç•™ï¼š\(AP\bot AB\)ï¼Œ\(AP\bot AD\) ï¼ˆä¸¤ä¸ªç‹¬ç«‹å—ï¼Œä¸åº”ä¿®æ”¹ï¼‰
    - ä»…ä¿®å¤çœŸæ­£åå‘çš„ï¼šæ±‚ç‚¹\) X_2 \(æ‰€æœ‰å¯èƒ½ â†’ æ±‚ç‚¹\( X_2 \)æ‰€æœ‰å¯èƒ½

    å®‰å…¨æ€§ï¼šä½¿ç”¨å®šç•Œç¬¦å¹³è¡¡æ£€æŸ¥ï¼Œç¡®ä¿åªä¿®å¤çœŸæ­£æ‚¬ç©ºçš„å®šç•Œç¬¦å¯¹
    """
    if not text:
        return text

    import re

    # é€è¡Œå¤„ç†ï¼Œé¿å…è·¨è¡ŒåŒ¹é…å¸¦æ¥çš„å¤æ‚æ€§
    lines = text.split('\n')
    fixed_lines = []

    for line in lines:
        # è·³è¿‡æ³¨é‡Šè¡Œ
        if line.strip().startswith('%'):
            fixed_lines.append(line)
            continue

        # ğŸ†• v1.9.5ï¼šè·³è¿‡å¤šè¡Œæ•°å­¦å—çš„ä¸­é—´è¡Œ
        # å¦‚æœè¡ŒåŒ…å« \begin{array/cases æˆ– \end{array/cases}ï¼Œè¯´æ˜æ˜¯å¤šè¡Œå—çš„ä¸€éƒ¨åˆ†
        # è¿™äº›è¡Œçš„å®šç•Œç¬¦å¯èƒ½æ˜¯è·¨è¡Œé…å¯¹çš„ï¼Œä¸åº”è¯¥æŒ‰å•è¡Œå¤„ç†
        if re.search(r'\\begin\{(array|cases|matrix|pmatrix|bmatrix|vmatrix)', line) or \
           re.search(r'\\end\{(array|cases|matrix|pmatrix|bmatrix|vmatrix)', line):
            fixed_lines.append(line)
            continue

        # æ‰¾åˆ°æ‰€æœ‰å®šç•Œç¬¦çš„ä½ç½®
        delimiters = []
        for m in re.finditer(r'\\\(|\\\)', line):
            delimiters.append((m.start(), m.group(0)))

        if len(delimiters) < 2:
            fixed_lines.append(line)
            continue

        # ä½¿ç”¨æ ˆç®—æ³•æ‰¾åˆ°çœŸæ­£æ‚¬ç©ºçš„ \) å’Œ \(
        stack = []  # å­˜å‚¨æœªåŒ¹é… \( çš„ç´¢å¼•
        unmatched_close_indices = []  # å­˜å‚¨æ‚¬ç©º \) åœ¨ delimiters ä¸­çš„ç´¢å¼•
        unmatched_open_indices = []  # å­˜å‚¨æ‚¬ç©º \( åœ¨ delimiters ä¸­çš„ç´¢å¼•

        for i, (pos, delim) in enumerate(delimiters):
            if delim == r'\(':
                stack.append(i)
            else:  # \)
                if stack:
                    stack.pop()  # åŒ¹é…æˆåŠŸ
                else:
                    unmatched_close_indices.append(i)  # æ‚¬ç©ºçš„ \)

        # æ ˆä¸­å‰©ä½™çš„æ˜¯æ‚¬ç©ºçš„ \(
        unmatched_open_indices = stack

        # åªæœ‰å½“å­˜åœ¨æ‚¬ç©ºçš„ \) ä¸”ç´§éšå…¶åæœ‰æ‚¬ç©ºçš„ \( æ—¶ï¼Œæ‰è€ƒè™‘ä¿®å¤
        # æ‰¾åˆ° (æ‚¬ç©º\), æ‚¬ç©º\() é…å¯¹
        pairs_to_fix = []
        for close_idx in unmatched_close_indices:
            # æ‰¾ç´§éšå…¶åçš„æ‚¬ç©º \(
            for open_idx in unmatched_open_indices:
                if open_idx > close_idx:
                    # æ£€æŸ¥ä¸­é—´æ˜¯å¦åªæœ‰ç®€å•å†…å®¹ï¼ˆæ ‡ç‚¹ã€ç©ºç™½ã€ç®€å•å­—æ¯æ•°å­—ï¼‰
                    close_pos = delimiters[close_idx][0]
                    open_pos = delimiters[open_idx][0]
                    middle = line[close_pos + 2:open_pos]  # è·³è¿‡ \) çš„ä¸¤ä¸ªå­—ç¬¦

                    # å…è®¸ç©ºç™½ã€æ ‡ç‚¹ã€ç®€å•å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿ï¼ˆç±»ä¼¼å˜é‡åï¼‰
                    # ä½†ä¸å…è®¸å¤æ‚çš„ LaTeX å‘½ä»¤æˆ–åµŒå¥—å®šç•Œç¬¦
                    if re.fullmatch(r'[\s.,ï¼Œã€‚ï¼›;:ï¼šã€!?ï¼ï¼Ÿ"""\'\'ã€Šã€‹ï¼ˆï¼‰()â€¦â€”\-A-Za-z0-9_{}]*', middle or ''):
                        pairs_to_fix.append((close_idx, open_idx, middle))
                        break  # æ¯ä¸ªæ‚¬ç©º \) åªé…å¯¹ä¸€ä¸ªæ‚¬ç©º \(

        # ä»åå¾€å‰ä¿®å¤ï¼ˆä¿æŒä½ç½®æ­£ç¡®ï¼‰
        line_chars = list(line)
        for close_idx, open_idx, middle in reversed(pairs_to_fix):
            close_pos = delimiters[close_idx][0]
            open_pos = delimiters[open_idx][0]
            # æ›¿æ¢ \) ä¸º \(
            line_chars[close_pos:close_pos + 2] = list(r'\(')
            # æ›¿æ¢ \( ä¸º \)ï¼ˆæ³¨æ„ï¼šç”±äºå‰é¢çš„æ›¿æ¢ï¼Œé•¿åº¦ä¸å˜ï¼‰
            line_chars[open_pos:open_pos + 2] = list(r'\)')

        fixed_lines.append(''.join(line_chars))

    return '\n'.join(fixed_lines)




def collect_reversed_math_samples(text: str, slug: str = "") -> None:
    r"""ğŸ†• v1.8.8 / v1.9.9ï¼šæ£€æµ‹å¹¶è®°å½•åå‘æ•°å­¦å®šç•Œç¬¦æ¡ˆä¾‹ï¼ˆåªè®°å½•ï¼Œä¸ä¿®æ”¹ï¼‰

    ğŸ†• v1.9.9: P1-7 ä¿®å¤è¯¯æŠ¥é—®é¢˜
    - ä½¿ç”¨æ ˆç®—æ³•æ£€æµ‹çœŸæ­£çš„åå‘å®šç•Œç¬¦
    - æ­£å¸¸çš„ \(A\)ï¼Œ\(B\) æ¨¡å¼ä¸å†è¢«è¯¯æŠ¥
    - åªæ£€æµ‹æ‚¬ç©ºçš„ \) åç´§è·Ÿæ‚¬ç©ºçš„ \( çš„æƒ…å†µ

    Args:
        text: å®Œæ•´çš„ TeX æ–‡æœ¬
        slug: è¯•å· slugï¼ˆç”¨äºæ—¥å¿—æ–‡ä»¶åï¼‰
    """
    if not text or not slug:
        return

    import re

    lines = text.splitlines()
    reversed_cases = []

    for line_num, line in enumerate(lines, start=1):
        # åªè€ƒè™‘æ³¨é‡Šå‰çš„éƒ¨åˆ†
        content = line.split('%', 1)[0]
        if not content.strip():
            continue

        # ğŸ†• v1.9.9: ä½¿ç”¨æ ˆç®—æ³•æ£€æµ‹çœŸæ­£çš„åå‘å®šç•Œç¬¦
        # æ‰¾åˆ°æ‰€æœ‰å®šç•Œç¬¦ä½ç½®
        delimiters = []
        for m in re.finditer(r'\\\(|\\\)', content):
            delimiters.append((m.start(), m.group(0)))

        if len(delimiters) < 2:
            continue

        # ä½¿ç”¨æ ˆæ‰¾åˆ°æœªåŒ¹é…çš„å®šç•Œç¬¦
        stack = []
        unmatched_close = []  # æ‚¬ç©ºçš„ \) ç´¢å¼•

        for idx, (pos, delim) in enumerate(delimiters):
            if delim == r'\(':
                stack.append(idx)
            else:  # \)
                if stack:
                    stack.pop()
                else:
                    unmatched_close.append(idx)

        unmatched_open = stack  # å‰©ä½™æœªåŒ¹é…çš„ \(

        # æ£€æŸ¥æ˜¯å¦æœ‰æ‚¬ç©ºçš„ \) åé¢ç´§è·Ÿæ‚¬ç©ºçš„ \(ï¼ˆçœŸæ­£çš„åå‘å®šç•Œç¬¦ï¼‰
        for close_idx in unmatched_close:
            for open_idx in unmatched_open:
                if open_idx > close_idx:
                    close_pos = delimiters[close_idx][0]
                    open_pos = delimiters[open_idx][0]
                    between = content[close_pos+2:open_pos]
                    # åªæœ‰ä¸­é—´æ˜¯æ ‡ç‚¹/ç©ºç™½æ—¶æ‰è®¤ä¸ºæ˜¯åå‘å®šç•Œç¬¦
                    if re.match(r'^[\sï¼Œã€‚ï¼›ï¼šã€ï¼ï¼Ÿ\s]*$', between):
                        line_display = line[:100] + '...' if len(line) > 100 else line
                        reversed_cases.append(
                            f"Line {line_num}: Found reversed inline math \\)...\\("
                            f"\n  Between content: '{between}'"
                            f"\n  Line: {line_display}"
                        )
                    break

    # å¦‚æœæ‰¾åˆ°åå‘å®šç•Œç¬¦ï¼Œè®°å½•åˆ°æ—¥å¿—
    if reversed_cases:
        from pathlib import Path
        debug_dir = Path("word_to_tex/output/debug")
        debug_dir.mkdir(parents=True, exist_ok=True)
        log_file = debug_dir / f"{slug}_reversed_delimiters.log"

        with log_file.open("w", encoding="utf-8") as f:
            f.write(f"# Reversed Math Delimiters Detection Log for {slug}\n")
            f.write(f"# Total cases found: {len(reversed_cases)}\n")
            f.write(f"# Generated: {Path(__file__).name}\n")
            f.write("\n")

            for i, case in enumerate(reversed_cases, start=1):
                f.write(f"{'='*80}\n")
                f.write(f"Case #{i}:\n")
                f.write(case + "\n\n")

        # é™é»˜è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶





# ============================================================
# å¯¼å‡ºåˆ—è¡¨
# ============================================================

__all__ = [
    'CHINESE_MATH_SEPARATORS',
    'TokenType',
    'MathStateMachine',
    'math_sm',
    'fix_array_boundaries',
    'fix_broken_set_definitions',
    'fix_ocr_specific_errors',
    'fix_right_boundary_errors',
    'fix_unmatched_close_delimiters',
    'balance_array_and_cases_env',
    'fix_trig_function_spacing',
    'fix_greek_letter_spacing',
    'fix_bold_math_symbols',
    'fix_overset_arrow_vectors',
    'fix_specific_reversed_pairs',
    'fix_simple_reversed_inline_pairs',
    'collect_reversed_math_samples',
]
